{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "754dfed1-1df4-445b-a052-ee9c076f66e2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#Oil Extraction Production Forecasting\n",
    "<br/>\n",
    "<img src=\"https://www.nsenergybusiness.com/wp-content/uploads/sites/4/2022/07/refinery-ga56d4972f_640.jpg\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7bf4a4b0-2add-47da-b679-529edfd7edd7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#IMPORTANT! DO NOT CHANGE THESE VALUES!!!!\n",
    "catalog = \"workshop\"\n",
    "db = \"default\"\n",
    "current_user = dbutils.notebook.entry_point.getDbutils().notebook().getContext().tags().get(\"user\").get()\n",
    "\n",
    "#IMPORTANT! THIS NEEDS TO BE UNIQUE FOR EVERY PARTICIPANT!!!!\n",
    "#IMPORTANT! THIS NEEDS TO BE THE NAME OF THE TABLE YOU CREATED FOR THIS LAB!!!!\n",
    "src_table = \"ademianczuk_oil_yield\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7eb48a0c-3ad7-4aba-a74e-e9deb1e75c7b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import mlflow\n",
    "\n",
    "#Set a named experiment. We want to use the same experiment where we logged our feature artifacts\n",
    "mlflow.set_experiment(f\"/Users/{current_user}/Oil Extraction Production Forecasting\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b68dbb96-527b-428d-b07b-4b82f8eb63da",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from databricks.feature_engineering import FeatureEngineeringClient\n",
    "\n",
    "fe = FeatureEngineeringClient()\n",
    "\n",
    "#Read in our feature table with normalized & tranformed features for model training\n",
    "df = fe.read_table(\n",
    "  name=f'{catalog}.{db}.{src_table}_features_transformed'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c284813b-d20c-4648-aeb4-faa2a25c6c89",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Check skewness and kurtosis for the effect of our transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0f91d1c0-a5db-4bcf-a9d9-7395557efcc4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import skew, kurtosis\n",
    "\n",
    "# Load transformed data\n",
    "df_transformed = df.toPandas()\n",
    "\n",
    "# Define function to print skewness & kurtosis\n",
    "def check_distribution(df, feature):\n",
    "    print(f\"\\nFeature: {feature}\")\n",
    "    print(f\"  Skewness: {skew(df[feature]):.2f}\")\n",
    "    print(f\"  Kurtosis: {kurtosis(df[feature]):.2f}\")\n",
    "\n",
    "# Compare original vs. transformed features\n",
    "for feature in [\"yield_bbl\", \"precipitation\", \"temperature\"]:\n",
    "    print(\"\\nðŸ”¹ BEFORE Transformation:\")\n",
    "    check_distribution(df_transformed, feature)\n",
    "    \n",
    "    print(\"\\nâœ… AFTER Transformation:\")\n",
    "    check_distribution(df_transformed, f\"{feature}_transformed\")\n",
    "\n",
    "# Plot distributions\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 8))\n",
    "\n",
    "for i, feature in enumerate([\"yield_bbl\", \"precipitation\", \"temperature\"]):\n",
    "    sns.histplot(df_transformed[feature], bins=30, kde=True, ax=axes[0, i], color=\"red\")\n",
    "    axes[0, i].set_title(f\"Before Box-Cox: {feature}\")\n",
    "\n",
    "    sns.histplot(df_transformed[f\"{feature}_transformed\"], bins=30, kde=True, ax=axes[1, i], color=\"blue\")\n",
    "    axes[1, i].set_title(f\"After Box-Cox: {feature}\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ff775f0e-7b12-4e9b-af43-bef359e2720e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Next, we'll do a trial training run. All we're doing here is looking to see how the box-cox or yeo-johnson transforms affect the reliability of the trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4e76238c-7e0d-4ef4-8dfc-ecb1568629fd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "\n",
    "#Select features & target\n",
    "features_original = [\"temperature\", \"precipitation\"]\n",
    "features_transformed = [\"temperature_transformed\", \"precipitation_transformed\"]\n",
    "target = \"yield_bbl\"\n",
    "\n",
    "#Load datasets\n",
    "df_transformed = df.toPandas()\n",
    "\n",
    "#Train-test split\n",
    "X_train_orig, X_test_orig, y_train_orig, y_test_orig = train_test_split(df_transformed[features_original], df_transformed[target], test_size=0.2, random_state=42)\n",
    "X_train_trans, X_test_trans, y_train_trans, y_test_trans = train_test_split(df_transformed[features_transformed], df_transformed[target], test_size=0.2, random_state=42)\n",
    "\n",
    "# Train XGBoost models\n",
    "model_orig = xgb.XGBRegressor(objective=\"reg:squarederror\", n_estimators=100, learning_rate=0.1)\n",
    "model_trans = xgb.XGBRegressor(objective=\"reg:squarederror\", n_estimators=100, learning_rate=0.1)\n",
    "\n",
    "model_orig.fit(X_train_orig, y_train_orig)\n",
    "model_trans.fit(X_train_trans, y_train_trans)\n",
    "\n",
    "# Predictions\n",
    "y_pred_orig = model_orig.predict(X_test_orig)\n",
    "y_pred_trans = model_trans.predict(X_test_trans)\n",
    "\n",
    "# Compute Errors\n",
    "mae_orig = mean_absolute_error(y_test_orig, y_pred_orig)\n",
    "rmse_orig = mean_squared_error(y_test_orig, y_pred_orig, squared=False)\n",
    "\n",
    "mae_trans = mean_absolute_error(y_test_trans, y_pred_trans)\n",
    "rmse_trans = mean_squared_error(y_test_trans, y_pred_trans, squared=False)\n",
    "\n",
    "# Print Results\n",
    "print(\"\\nðŸ”¹ Model Performance (Without Box-Cox):\")\n",
    "print(f\"  MAE: {mae_orig:.2f}, RMSE: {rmse_orig:.2f}\")\n",
    "\n",
    "print(\"\\nâœ… Model Performance (With Box-Cox):\")\n",
    "print(f\"  MAE: {mae_trans:.2f}, RMSE: {rmse_trans:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8036034a-cf30-4e52-bf38-e2b607d709a5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Lab Challenge: How could we further improve MAE and RMSE?\n",
    "- Further adjustments to features?\n",
    "- HP tuning?\n",
    "- Yeo Johnson?\n",
    "- What other algorithms might be better? LSTM for DNN processing?\n",
    "- What's causing noise?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9baa438f-8f98-4e3d-82f1-d0a8ad86b972",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Tuning and managing our experiment\n",
    "MLFlow is key, and using hyperopt or optuna are good for distributed hyperparameter tuning. In the next notebook, we'll be setting up an MLFlow experiment for training and tuning out model."
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "03_Transformation_Evaluation",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
