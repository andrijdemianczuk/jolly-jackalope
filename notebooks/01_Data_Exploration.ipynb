{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8a2e4015-e240-4f5e-ae1c-456cfb6d3692",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#Oil Extraction Production Forecasting\n",
    "<br/>\n",
    "<img src=\"https://www.nsenergybusiness.com/wp-content/uploads/sites/4/2022/07/refinery-ga56d4972f_640.jpg\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b9705113-2d82-4e6e-844e-c980887f74cc",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Initialization"
    }
   },
   "outputs": [],
   "source": [
    "catalog = \"workshop\"\n",
    "db = \"default\"\n",
    "src_table = \"ademianczuk_oil_yield\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0283d0f9-78a4-498e-8ba0-231ca22859ed",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#Load the delta table into a PySpark dataframe\n",
    "df = spark.table(f\"{catalog}.{db}.{src_table}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7e26d668-1f88-4a0a-b34d-a7496e0ff655",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df.printSchema()\n",
    "df.show(5, truncate=False)  # Display first 5 rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7bec5226-7fee-4500-b4b5-77d302c58e3b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "display(df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "035f7bba-9612-404f-8bcb-64ec53516761",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# If any columns have missing values, we need to decide whether to fill, drop, or interpolate them. Sometimes empty or missing values may be valuable though.\n",
    "\n",
    "from pyspark.sql.functions import col, sum\n",
    "\n",
    "df.select([sum(col(c).isNull().cast(\"int\")).alias(c) for c in df.columns]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "feb9ebcb-b5e8-4b36-b8b3-a6229a386f89",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "use a timeseries chart to preview seasonality"
    }
   },
   "outputs": [],
   "source": [
    "#Let's look for some seasonality based on the timeseries plot\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# Convert PySpark DataFrame to Pandas for plotting\n",
    "df_pd = df.select(\"date\", \"yield_bbl\").groupby(\"date\").avg(\"yield_bbl\").orderBy(\"date\").toPandas()\n",
    "\n",
    "# Plot time series\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.plot(df_pd[\"date\"], df_pd[\"avg(yield_bbl)\"], marker=\"o\", linestyle=\"-\")\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"Average Yield (BBL)\")\n",
    "plt.title(\"Oil Yield Trend Over Time\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6e91b84b-aa58-4c4d-ba3c-649f76654e16",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "downsample and show temperature and precipitation"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# Convert PySpark DataFrame to Pandas\n",
    "df_pd = df.select(\"date\", \"temperature\", \"precipitation\").toPandas()\n",
    "\n",
    "# Convert date to datetime\n",
    "df_pd[\"date\"] = pd.to_datetime(df_pd[\"date\"])\n",
    "\n",
    "# Resample to weekly average to reduce data size\n",
    "df_resampled = df_pd.set_index(\"date\").resample(\"W\").mean().reset_index()\n",
    "\n",
    "# Create figure and axes\n",
    "fig, ax1 = plt.subplots(figsize=(12, 5))\n",
    "\n",
    "# Plot temperature on primary y-axis\n",
    "ax1.plot(df_resampled[\"date\"], df_resampled[\"temperature\"], color=\"red\", marker=\"o\", linestyle=\"-\", label=\"Temperature (°C)\")\n",
    "ax1.set_xlabel(\"Date\")\n",
    "ax1.set_ylabel(\"Temperature (°C)\", color=\"red\")\n",
    "ax1.tick_params(axis=\"y\", labelcolor=\"red\")\n",
    "\n",
    "# Create secondary y-axis for precipitation\n",
    "ax2 = ax1.twinx()\n",
    "ax2.bar(df_resampled[\"date\"], df_resampled[\"precipitation\"], color=\"blue\", alpha=0.5, label=\"Precipitation (mm)\")\n",
    "ax2.set_ylabel(\"Precipitation (mm)\", color=\"blue\")\n",
    "ax2.tick_params(axis=\"y\", labelcolor=\"blue\")\n",
    "\n",
    "# Title and layout\n",
    "plt.title(\"Temperature and Precipitation Over Time (Weekly Avg)\")\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "16f05ee1-0d16-400d-b4b9-b973b810c9f1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# We need to check for abnormally high or low values in oil yield (barrels produced), well pressure and oil price.\n",
    "# Convert to Pandas for visualization\n",
    "df_outliers = df.select([\"yield_bbl\", \"temperature\", \"well_pressure\", \"oil_price\"]).toPandas()\n",
    "\n",
    "# Plot boxplots\n",
    "df_outliers.plot(kind=\"box\", subplots=True, layout=(2, 2), figsize=(10, 8), sharex=False, sharey=False)\n",
    "plt.suptitle(\"Box Plot of Key Features\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0a73c1ff-69d3-411d-82c7-6b9df284cca2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Let's look for some field correlation\n",
    "import seaborn as sns\n",
    "\n",
    "# Convert PySpark DF to Pandas\n",
    "df_corr = df.select([\"yield_bbl\", \"temperature\", \"precipitation\", \"humidity\", \"wind_speed\", \"well_pressure\", \"sand_quality\", \"drilling_efficiency\", \"oil_price\"]).toPandas()\n",
    "\n",
    "# Plot heatmap\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.heatmap(df_corr.corr(), annot=True, cmap=\"coolwarm\", fmt=\".2f\", linewidths=0.5)\n",
    "plt.title(\"Feature Correlation Heatmap\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0d6bce76-97b7-45aa-be13-076c939ac127",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "# Convert PySpark DataFrame to Pandas\n",
    "df_pd = df.select(\"yield_bbl\", \"temperature\", \"precipitation\").toPandas()\n",
    "\n",
    "# Create the KDE plot (bell curve)\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Plot yield distribution\n",
    "sns.kdeplot(df_pd[\"yield_bbl\"], label=\"Yield (BBL)\", color=\"red\", linewidth=2)\n",
    "\n",
    "# Labels and title\n",
    "plt.xlabel(\"Value\")\n",
    "plt.ylabel(\"Density\")\n",
    "plt.title(\"Bell Curve of Yield\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "# Show plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3b311257-2028-46d7-9b14-a3154f0990d8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "# Convert PySpark DataFrame to Pandas\n",
    "df_pd = df.select(\"yield_bbl\", \"temperature\", \"precipitation\").toPandas()\n",
    "\n",
    "# Create the KDE plot (bell curve)\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Plot yield distribution\n",
    "sns.kdeplot(df_pd[\"temperature\"], label=\"Temperature\", color=\"green\", linewidth=2)\n",
    "\n",
    "# Labels and title\n",
    "plt.xlabel(\"Value\")\n",
    "plt.ylabel(\"Density\")\n",
    "plt.title(\"Bell Curve of temperature\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "# Show plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3ce026c9-0e64-44e8-ba65-8e0349353307",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "# Convert PySpark DataFrame to Pandas\n",
    "df_pd = df.select(\"yield_bbl\", \"temperature\", \"precipitation\").toPandas()\n",
    "\n",
    "# Create the KDE plot (bell curve)\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Plot yield distribution\n",
    "sns.kdeplot(df_pd[\"precipitation\"], label=\"Precipitation (mm)\", color=\"blue\", linewidth=2)\n",
    "\n",
    "# Labels and title\n",
    "plt.xlabel(\"Value\")\n",
    "plt.ylabel(\"Density\")\n",
    "plt.title(\"Bell Curve of precipitation\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "# Show plot\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "01_Data_Exploration",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
