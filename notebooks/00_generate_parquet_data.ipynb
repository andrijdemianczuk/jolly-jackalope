{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "51b24c2f-fff8-4cfe-83c1-79211eb3ca1d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#Oil Extraction Production Forecasting\n",
    "<br/>\n",
    "<img src=\"https://www.nsenergybusiness.com/wp-content/uploads/sites/4/2022/07/refinery-ga56d4972f_640.jpg\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7619ab3c-1bf5-4dd9-bee3-841da06adcad",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Synthetic Data Generation\n",
    "\n",
    "This script generates a synthetic dataset and stores the result in a parquet file / structure. This gives us the flexibility to take a variety of approaches in terms of ingesting the data. Two options may be:\n",
    "1. Reading the newly landed parquet data using autoloader / cloudfiles\n",
    "1. Converting the directory to a delta format for easy delta table registration.\n",
    "\n",
    "Working with CSV data is very similar in terms of updating and appending data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "48aaffaa-2b59-4a61-a1e5-6b074c796647",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import os\n",
    "import glob\n",
    "import pyarrow.parquet as pq\n",
    "import pyarrow as pa\n",
    "\n",
    "# Configuration\n",
    "NUM_WELLS = 100  # Number of well sites\n",
    "DAYS_TO_ADD = 3650  # Number of new days to simulate per run\n",
    "OUTPUT_DIR = \"../data/synthetic_oil_yield_parquet_files\"  # Directory to store multiple files\n",
    "\n",
    "# Ensure output directory exists\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "def get_latest_end_date():\n",
    "    \"\"\"Finds the latest recorded date for each well from the most recent Parquet file.\"\"\"\n",
    "    parquet_files = sorted(glob.glob(os.path.join(OUTPUT_DIR, \"synthetic_oil_yield_*.parquet\")), reverse=True)\n",
    "    \n",
    "    if parquet_files:\n",
    "        latest_file = parquet_files[0]  # Most recent file\n",
    "        df = pq.read_table(latest_file).to_pandas()\n",
    "        \n",
    "        # Get the last recorded date per well\n",
    "        last_dates = df.groupby(\"well_id\")[\"date\"].max().to_dict()\n",
    "        print(f\"Loaded last recorded dates from {latest_file}\")\n",
    "        \n",
    "        return last_dates\n",
    "    else:\n",
    "        return None  # No previous data found\n",
    "\n",
    "def generate_synthetic_data(num_wells, last_dates, days):\n",
    "    \"\"\"Generates new synthetic data starting from the next day after the last recorded date for each well.\"\"\"\n",
    "    np.random.seed(None)  # Ensures randomness per execution\n",
    "\n",
    "    well_ids = [f\"WELL_{i+1:03d}\" for i in range(num_wells)]\n",
    "    records = []\n",
    "\n",
    "    for well_id in well_ids:\n",
    "        start_date = last_dates.get(well_id, datetime.datetime(2015, 1, 1)) + datetime.timedelta(days=1)\n",
    "\n",
    "        base_yield = np.random.uniform(100, 500)  # Base yield per well\n",
    "        base_pressure = np.random.uniform(2500, 3500)  # Well pressure in psi\n",
    "\n",
    "        for day in range(days):\n",
    "            date = start_date + datetime.timedelta(days=day)\n",
    "\n",
    "            # Time-based seasonality\n",
    "            day_of_year = date.timetuple().tm_yday\n",
    "\n",
    "            # Environmental Factors\n",
    "            temperature = round(10 + 15 * np.sin(2 * np.pi * day_of_year / 365) + np.random.normal(0, 3), 1)\n",
    "            precipitation = max(0, np.random.normal(5, 10) if day_of_year in range(90, 180) else np.random.normal(2, 5))\n",
    "            humidity = round(np.random.uniform(30, 90), 1)\n",
    "            wind_speed = round(np.random.uniform(5, 25), 1)\n",
    "\n",
    "            # Operational Factors\n",
    "            well_pressure = max(2000, base_pressure + np.random.normal(0, 50))\n",
    "            downtime = np.random.choice([0, 0, 0, 2, 4, 8, 12], p=[0.8, 0.05, 0.05, 0.02, 0.03, 0.025, 0.025])\n",
    "            sand_quality = round(np.random.uniform(75, 95), 1)\n",
    "            drilling_efficiency = round(np.random.uniform(80, 98), 1)\n",
    "\n",
    "            # External Factors\n",
    "            oil_price = round(np.random.uniform(50, 120), 2)\n",
    "            regulatory_impact = np.random.choice([0, 1], p=[0.95, 0.05])\n",
    "\n",
    "            # Yield Calculation\n",
    "            seasonal_variation = 20 * np.sin(2 * np.pi * day_of_year / 365)\n",
    "            noise = np.random.normal(0, 10)\n",
    "            well_downtime_impact = 1 - (downtime / 24)\n",
    "            quality_impact = (sand_quality / 100)\n",
    "            efficiency_impact = (drilling_efficiency / 100)\n",
    "\n",
    "            # Final Yield Calculation\n",
    "            daily_yield = max(50, base_yield * seasonal_variation * well_downtime_impact * quality_impact * efficiency_impact + noise)\n",
    "\n",
    "            # Append record\n",
    "            records.append((well_id, date, round(daily_yield, 2), temperature, precipitation, humidity, wind_speed,\n",
    "                            well_pressure, downtime, sand_quality, drilling_efficiency, oil_price, regulatory_impact))\n",
    "\n",
    "    # Create DataFrame\n",
    "    df = pd.DataFrame(records, columns=[\"well_id\", \"date\", \"yield_bbl\", \"temperature\", \"precipitation\", \"humidity\", \n",
    "                                        \"wind_speed\", \"well_pressure\", \"downtime\", \"sand_quality\", \n",
    "                                        \"drilling_efficiency\", \"oil_price\", \"regulatory_impact\"])\n",
    "\n",
    "    return df\n",
    "\n",
    "# Get last recorded date per well (if available)\n",
    "last_dates = get_latest_end_date() or {}\n",
    "\n",
    "# Generate new data starting from the next available date\n",
    "new_data = generate_synthetic_data(NUM_WELLS, last_dates, DAYS_TO_ADD)\n",
    "\n",
    "# Define filename with timestamp\n",
    "current_run_timestamp = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "output_file = os.path.join(OUTPUT_DIR, f\"synthetic_oil_yield_{current_run_timestamp}.parquet\")\n",
    "\n",
    "# Write to a new Parquet file\n",
    "table = pa.Table.from_pandas(new_data)\n",
    "pq.write_table(table, output_file)\n",
    "\n",
    "print(f\"Generated {len(new_data)} new records and saved to {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "37fb3e07-2a13-487d-adc7-05b6d972408c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "new_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "eeb67390-9f86-4165-8e5e-48acf8f11396",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "current_user = dbutils.notebook.entry_point.getDbutils().notebook().getContext().userName().get()\n",
    "print (current_user)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "00_generate_parquet_data",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
